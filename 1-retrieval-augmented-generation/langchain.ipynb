{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List, Mapping, Optional\n",
    "import langchain\n",
    "import requests\n",
    "from langchain.llms.base import LLM\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniLML6V2EmbeddingFunctionLangchain(langchain.embeddings.openai.Embeddings):\n",
    "    MODEL = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        return MiniLML6V2EmbeddingFunctionLangchain.MODEL.encode(texts).tolist()\n",
    "\n",
    "    def embed_query(self, query):\n",
    "        return MiniLML6V2EmbeddingFunctionLangchain.MODEL.encode([query]).tolist()[0]\n",
    "\n",
    "\n",
    "class IBMWatsonX(LLM):\n",
    "    api_key: str\n",
    "    model_name: str\n",
    "    project_id: str\n",
    "    model_parameters: Mapping[str, Any]\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"IBM watsonx.ai\"\n",
    "\n",
    "    def _get_token(self) -> str:\n",
    "        url = \"https://iam.cloud.ibm.com/identity/token\"\n",
    "        headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "        data = (\n",
    "            f\"apikey={self.api_key}&grant_type=urn:ibm:params:oauth:grant-type:apikey\"\n",
    "        )\n",
    "        response = requests.post(url, headers=headers, data=data)\n",
    "        iam_token = response.json()[\"access_token\"]\n",
    "        return iam_token\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "    ) -> str:\n",
    "        iam_token = self._get_token()\n",
    "        url = \"https://us-south.ml.cloud.ibm.com/ml/v1-beta/generation/text?version=2023-05-29\"\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Accept\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {iam_token}\",\n",
    "        }\n",
    "        payload = {\n",
    "            \"model_id\": self.model_name,\n",
    "            \"input\": prompt,\n",
    "            \"parameters\": self.model_parameters,\n",
    "            \"project_id\": self.project_id,\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, headers=headers, json=payload)\n",
    "        return response.json()[\"results\"][0][\"generated_text\"]\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        return {\"model_name\": self.model_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"xxx\"\n",
    "temperature = 0.0\n",
    "model_name = \"google/flan-ul2\"\n",
    "project_id = \"3dce5aff-e4a0-48fc-9210-445d52ef0c34\"\n",
    "model_parameters = {\n",
    "    \"decoding_method\": \"sample\",\n",
    "    \"max_new_tokens\": 200,\n",
    "    \"min_new_tokens\": 1,\n",
    "    \"random_seed\": 12345,\n",
    "    \"stop_sequences\": [],\n",
    "    \"temperature\": temperature,\n",
    "    \"top_k\": 50,\n",
    "    \"top_p\": 1,\n",
    "    \"repetition_penalty\": 1,\n",
    "}\n",
    "\n",
    "llm_ibm = IBMWatsonX(\n",
    "    api_key=api_key,\n",
    "    model_name=model_name,\n",
    "    model_parameters=model_parameters,\n",
    "    project_id=project_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"../data/Happy-Hunt-T-Cs-Final-1.pdf\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=10)\n",
    "texts = text_splitter.split_documents(loader.load())\n",
    "db = FAISS.from_documents(texts, MiniLML6V2EmbeddingFunctionLangchain())\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_ibm = RetrievalQA.from_chain_type(\n",
    "    llm=llm_ibm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the duration of the Campaign?\"\n",
    "\n",
    "result = qa_ibm({\"query\": question})\n",
    "\n",
    "result[\"result\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
